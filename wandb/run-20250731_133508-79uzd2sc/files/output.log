  0%|                                                                                                                                                                           | 0/300 [00:00<?, ?it/s]/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.
  warnings.warn(warn_msg)
INPUTS: dict_keys(['input_ids', 'attention_mask', 'labels', 'num_items_in_batch'])
Traceback (most recent call last):
  File "/home/szhifan/eic_classification/ft.py", line 183, in <module>
    main()
  File "/home/szhifan/eic_classification/ft.py", line 167, in main
    model_finetuner.fine_tune(model, tokenizer, train_ds = train_ds , val_ds = val_ds,  lora_r = lora_r, lora_alpha = lora_alpha, lora_dropout = lora_dropout,
  File "/home/szhifan/eic_classification/finetuning_llm_seqc/model_finetuner.py", line 153, in fine_tune
    train_result = trainer.train()
                   ^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/transformers/trainer.py", line 2579, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/transformers/trainer.py", line 3793, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/transformers/trainer.py", line 3881, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/peft/peft_model.py", line 1559, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/peft/tuners/tuners_utils.py", line 193, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/transformers/utils/generic.py", line 961, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/transformers/modeling_layers.py", line 124, in forward
    transformer_outputs: BaseModelOutputWithPast = getattr(self, self.base_model_prefix)(
                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/szhifan/miniconda3/envs/work/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LlamaModel.forward() got an unexpected keyword argument 'num_items_in_batch'
